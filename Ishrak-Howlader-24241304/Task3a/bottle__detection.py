# -*- coding: utf-8 -*-
"""plastic_bottle _detection

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16p5F8gq1rUN2fzQz9cqDC4doqwtoObOd
"""

!pip install kaggle

#api calling for kaggle
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# Dataset 1: ~8k outdoor plastic bottles
!kaggle datasets download -d siddharthkumarsah/plastic-bottles-image-dataset -p /content/data1 --unzip
#dataset - 2
!kaggle datasets download -d arkadiyhacks/drinking-waste-classification -p /content/data2 --unzip

# List top–level folders & files for each
!find /content/data1 -maxdepth 2 | sed 's/^/  /'
!find /content/data2 -maxdepth 2 | sed 's/^/  /'

# what kind of files there is in
# Dataset 1
!find "/content/data1/Plastic Bottle Image Dataset" -maxdepth 2 | sed 's/^/  /'

# Dataset 2
!find /content/data2/Images_of_Waste/YOLO_imgs -maxdepth 1 | sed 's/^/  /'

# binding the two datasets together

import os, shutil, re

SRC = "/content/data2/Images_of_Waste/YOLO_imgs"
DST_IMG = "/content/data2/Images_of_Waste/PET_only/images"
DST_LBL = "/content/data2/Images_of_Waste/PET_only/labels"

os.makedirs(DST_IMG, exist_ok=True)
os.makedirs(DST_LBL, exist_ok=True)

for fname in os.listdir(SRC):
    # pick only PET images
    if fname.lower().startswith("pet") and fname.lower().endswith((".jpg",".jpeg",".png")):
        # strip commas from the name
        clean = re.sub(r",", "", fname)
        # copy image
        shutil.copy(os.path.join(SRC, fname), os.path.join(DST_IMG, clean))
        # handle its label
        lbl_src = os.path.join(SRC, fname.rsplit(".",1)[0] + ".txt")
        if os.path.exists(lbl_src):
            clean_lbl = re.sub(r",", "", os.path.basename(lbl_src))
            lines = []
            with open(lbl_src) as f:
                for line in f:
                    parts = line.strip().split()
                    # assume PET was class '1'; remap to '0'
                    if parts[0] == '1':
                        parts[0] = '0'
                        lines.append(" ".join(parts))
            # write new label file
            with open(os.path.join(DST_LBL, clean_lbl), "w") as out:
                out.write("\n".join(lines))

#creating mixed data directory
!mkdir -p /content/bottle_data/{images,labels}/{train,val}

import glob, os, random, shutil

# 1) Dataset 1 splits
d1 = "/content/data1/Plastic Bottle Image Dataset"
pairs = []
for split, sub in [('train','train'), ('val','valid')]:
    img_dir = f"{d1}/{sub}/images"
    lbl_dir = f"{d1}/{sub}/labels"
    for img in glob.glob(f"{img_dir}/*.jpg"):
        lbl = os.path.join(lbl_dir, os.path.basename(img).replace('.jpg','.txt'))
        if os.path.exists(lbl):
            pairs.append((img, lbl, split))

# 2) Dataset 2 cleaned: all go into train
d2_img = "/content/data2/Images_of_Waste/plastic_only/images"
d2_lbl = "/content/data2/Images_of_Waste/plastic_only/labels"
for img in glob.glob(f"{d2_img}/*.jpg"):
    lbl = os.path.join(d2_lbl, os.path.basename(img).replace('.jpg','.txt'))
    if os.path.exists(lbl):
        pairs.append((img, lbl, 'train'))

# 3) Shuffle and copy
random.shuffle(pairs)
for img, lbl, split in pairs:
    dst_img = f"/content/bottle_data/images/{split}/{os.path.basename(img)}"
    dst_lbl = f"/content/bottle_data/labels/{split}/{os.path.basename(lbl)}"
    shutil.copy(img, dst_img)
    shutil.copy(lbl, dst_lbl)

print(f"Total → train: {len([p for p in pairs if p[2]=='train'])}, val: {len([p for p in pairs if p[2]=='val'])}")

!find /content/bottle_data -maxdepth 3 | sed 's/^/  /'

yaml_content = """
path: /content/bottle_data
train: images/train
val: images/val

nc: 1
names: ['bottle']
"""

with open('/content/bottle.yaml', 'w') as f:
    f.write(yaml_content.strip())

!pip install ultralytics

#training the data
from ultralytics import YOLO

# Load a pretrained model (nano)
model = YOLO('yolov8n.pt')

# Train on your plastic-bottle dataset
results = model.train(
    data    = '/content/bottle.yaml',
    epochs  = 20,       # adjust as needed
    imgsz   = 640,
    batch   = 16,       # adjust to your GPU/TPU memory
    project = 'bottle-detect',
    name    = 'v8n-plastic',
    device  = 0         # or 'cpu'
)

from ultralytics import YOLO

# Load your best-trained weights
model = YOLO('/content/bottle-detect/v8n-plastic/weights/best.pt')

# Validate on the val split defined in bottle.yaml
metrics = model.val(data='/content/bottle.yaml',  # uses val: images/val
                    iou=0.5,                     # IoU threshold for mAP@0.5
                    conf=0.25,                   # confidence threshold
                    batch=16)

print(metrics)  # prints mAP, precision, recall, F1, etc.

from ultralytics import YOLO
from IPython.display import Image, display
import glob

# Load your trained model
model = YOLO('/content/bottle-detect/v8n-plastic/weights/best.pt')

# Run inference
results = model('/content/istockphoto-1176700286-612x612.jpg',
                conf=0.25,
                iou=0.45,
                save=True,
                save_txt=True)

# Get save_dir from the first result
output_dir = results[0].save_dir  # ✅ fixed: access first result

# Find the predicted image
predicted_image = glob.glob(f"{output_dir}/*.jpg")[0]

# Display it inline
display(Image(filename=predicted_image))